# linear-regression
linear regression, 즉 선형회귀는 독립변수에 대한 종속변수의 상관관계를 모델링하는 회귀분석 기법 중 하나이다.  
엑셀이나 통계 관련 툴에서는 가장 기본적으로 접할 수 있고, 고등학교 수준의 수학으로도 쉽게 이해할 수 있다!  

필요역량: 미분의 정의와 기하학적 의미, 실제 사용법/ 파이썬을 활용한 반복문, 함수 작성 능력과 그래프로 시각화하는 능력  

# 간단한 원리
(x,y) 형태의 데이터가 여러 개 있다고 생각하자.  
(1,2), (2,5), (3,6)...  
이 데이터들을 가장 잘 설명할 수 있는 그래프(직선)을 찾아내는게 선형회귀이다.  

1. 먼저 아무 직선이나 그린다.(기울기와 y절편을 랜덤으로 지정한다)  
2. 그 직선을 f(x)라고 했을때, 데이터 (1,2)에 대해서 f(1)=3이라면 오차는 -1이 된다.
3. 우리가 필요한 것은 오차의 절댓값이므로 모든 데이터에 대해서 오차를 계산한 다음 제곱해서 더해준다. 이를 *비용함수*라고 한다.
4. 비용함수는 기울기 a와 y절편 b에 대한 이차함수가 된다(이차항의 계수는 양수이다). 이차함수의 개형을 머릿속에 떠올려보자. 이차함수는 꼭짓점에서 최솟값을 가진다. 그러므로 그 점에서 비용이 최소가 된다는 뜻이고, 곧 그 점에서의 기울기와 y절편이 데이터를 가장 잘 설명할 수 있는 직선을 의미하게 된다.
5. 그래서, 비용함수(이차함수)의 최솟값을 찾는게 관건인데, 그냥 꼭짓점을 계산하기에는 변수가 두 개이기도 하고 실제 통계학에서 사용할 때는 이차함수가 아닐수도 있다. 그래서 최솟값을 찾기 위해 *경사하강법*을 사용한다.
6. 경사하강법은 최솟값(극솟값)에 가까워질수록 접선의 기울기의 값이(미분계수의 값이) 0으로 수렴한다는 사실을 이용한 최솟값 찾기 방법이다. 비용함수의 아무 점을 시작점으로 잡고 그 점에서의 미분계수를 계산한 다음, 기울기 부호의 반대쪽으로 기울기 절댓값x상수 만큼 이동한다. 즉 -기울기x상수 만큼 이동한다는 것이 된다.
7. 비용함수는 기울기와 y절편, 두가지가 모두 변수이다. 따라서 두 변수에 대해 따로 미분해주고, 그 식을 이용해서 경사하강법을 수행한다.
8. 기본적으로 1000번 이상(사실 나는 1000번으로 했다가 오류를 발견했다), 10000번 정도는 이동을 반복해줘야 최솟값을 정확히 찾을 수 있다. 
